{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Import libraries\nimport os\nimport numpy as np\nimport pandas as pd\nfrom itertools import product\n\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import make_scorer\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras import optimizers\n\nfrom utils import load_image, get_centers, coord_transfm, draw_roi, mirror\nfrom simplecnn import SimpleCNN\nfrom resnet50 import ResNet50, Eucl_distance_tensor, Eucl_distance\nfrom model_tuning import plot_history, plot_roi_centers\n\n% matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Define global parameters\n\nIMG_WIDTH = 32\nIMG_HEIGHT = 32\nIMG_CHANNELS = 1\nTRAIN_SIZE = 5000\nTRAIN_PATH = '../input/bone-lab/trainset/'\nTEST_PATH = '../input/bone-lab/testset/'\nROI_PATH = \"../input/bone-lab/roi/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load and pre-process data/images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read and load ROI data\ndf_centers_org = get_centers(ROI_PATH).sort_values(by='img_id') \\\n                                      .reset_index(drop=True)\nprint(df_centers_org.head())\ndf_centers = coord_transfm(df_centers_org)\nprint(df_centers.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check every image matches the ROI file\nimages = pd.Series(sorted(os.listdir(TRAIN_PATH)))\nimg_ids = images.str.split('.').str[0]\nassert df_centers.img_id.equals(img_ids), \"Image lists don't match\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Randomly pick training samples from the trainset\ntrain_images = images.sample(TRAIN_SIZE, random_state=10)\ntrain_img_ids = train_images.str.split('.').str[0]\n\n# Load the selected images and reduce resolution\nmat_images = load_image(TRAIN_PATH, train_images, IMG_HEIGHT, IMG_WIDTH)\n\n# Store all images into a dataframe\ndf_train = pd.DataFrame(mat_images, \n                        columns=['pxl' + str(i) for i in range(mat_images.shape[1])])\ndf_train.insert(0, 'img_id', train_img_ids.values)\ndf_train = pd.merge(df_train, df_centers[['img_id', 'cx', 'cy']], \n                    on='img_id', validate=\"1:1\")\nprint(df_train.head())\nprint(df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Manual data augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Flip all train images around horizontal direction\ndf_train_hflip = mirror(df_train, 'h', IMG_HEIGHT, IMG_WIDTH)\n\n# Flip all train images around horizontal direction\ndf_train_vflip = mirror(df_train, 'v', IMG_HEIGHT, IMG_WIDTH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge original and reproduced images\ndf_train = pd.concat([df_train, df_train_hflip, df_train_vflip],\n                     ignore_index=True)\nprint(\"New dataframe's shape: {}\".format(df_train.shape))\ndf_centers = df_train[['img_id', 'cx', 'cy']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert all images and their ROI centers into Numpy ndarray\nX = df_train.drop(columns=['img_id', 'cx', 'cy']) \\\n            .values.reshape((-1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\nY = df_train[['cx', 'cy']].values\nIDs = df_train.img_id.values\n\n# Normalization\nX /= 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Free RAM space\ndel df_train, df_train_hflip, df_train_vflip, mat_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train and validation sets\nX_train, X_val, Y_train, Y_val, IDs_train, IDs_val \\\n= train_test_split(X, Y, IDs, test_size=0.1, random_state=1)\n\nprint(\"Trainset shape: {}\".format(X_train.shape))\nprint(\"Validateset shape: {}\".format(X_val.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display some sample images with known ROI\nselect_disp = df_centers.iloc[:TRAIN_SIZE].sample(n=3)\nimg_list = select_disp['img_id'].values\ntrue_centers = select_disp[['cx', 'cy']].values\ndraw_roi(TRAIN_PATH, img_list, true_centers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Baseline model: Simple CNN\n**Architechture:** \n\n    Input -> ((Conv2D->relu) x 2 -> MaxPool2D) x 2 -> Flatten -> Dense x 2 -> Output"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the model\nsimple_cnn = SimpleCNN(INPUT_SHAPE=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\nsimple_cnn.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Fit the model with learning rate to be reduced when no progress\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n                              patience=5, min_lr=0.0001)\nhist_cnn = simple_cnn.fit(X_train, Y_train, batch_size=64, epochs=100,\n                          validation_split=0.2, callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model with validation set\ncnn_scores_train = simple_cnn.evaluate(X_train, Y_train)\nprint(\"Score on trainset: {}\".format(cnn_scores_train))\n\ncnn_scores_val = simple_cnn.evaluate(X_val, Y_val)\nprint(\"Score on validate set: {}\".format(cnn_scores_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_pred = simple_cnn.predict(X_val, verbose=True)\ncnn_results = pd.DataFrame(np.concatenate([cnn_pred, Y_val], axis=1), \n                           columns = ['cx_pred', 'cy_pred', 'cx', 'cy'])\ncnn_results.insert(0, 'img_id', IDs_val)\nprint(cnn_results.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize some results from the first model\norig = [img_id for img_id in cnn_results.img_id \n        if 'f' not in img_id]\norig_imgs = cnn_results[cnn_results.img_id.isin(orig)]\nselt_imgs = orig_imgs.sample(n=3)\nimg_list = selt_imgs['img_id'].values\ntrue_centers = selt_imgs[['cx', 'cy']].values\npred_centers = selt_imgs[['cx_pred', 'cy_pred']].values\n\ndraw_roi(TRAIN_PATH, img_list, true_centers, \n         pred_centers, rows=2, cols=3, model_name=\"Simple CNN\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the ROI centers that human determined (red) along with that model detected\nselt_dots = orig_imgs.sample(n=15)\nimg_list = selt_dots['img_id'].values\ntrue_centers = (selt_dots[['cx', 'cy']].values * 1330).astype(int)\npred_centers = (selt_dots[['cx_pred', 'cy_pred']].values * 1330).astype(int)\n\nplot_roi_centers(true_centers, pred_centers, \"Simple CNN\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the results of predictions\ncnn_results.to_csv(\"cnn_results.csv\")\n\n# Save the model into HDF5 file\nsimple_cnn.save(\"simple_cnn.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot training history on loss\nplot_history(hist_cnn, 'Simple CNN', xlim=(0,60), ylim=(0.0, 0.03))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Second model: ResNet-50\n**Architecture**\n\n    INPUT -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK x 2 -> CONVBLOCK -> \n    IDBLOCK x 3 -> CONVBLOCK -> IDBLOCK x 5 -> CONVBLOCK -> IDBLOCK x 2 -> AVGPOOL -> FC x 2 -> \n    Dropout -> Output\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the model instance\nresnet = ResNet50(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n                  lr_power=-2.5,\n                  extra_layers=(1024, 256, 32),\n                  dropouts=(0., 0., 0.))\nresnet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model with learning rate to be reduced when no progress\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n                              patience=5, min_lr=0.0001)\nhist_resnet = resnet.fit(X_train, Y_train, batch_size=32, epochs=120,\n                         validation_split=0.2, callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model with validation set\nResNet_scores_train = resnet.evaluate(X_train, Y_train, batch_size=512)\nprint(\"Score on trainset: {}\".format(ResNet_scores_train))\n\nResNet_scores_val = resnet.evaluate(X_val, Y_val)\nprint(\"Score on validate set: {}\".format(ResNet_scores_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ResNet_pred = resnet.predict(X_val, verbose=True)\nResNet_results = pd.DataFrame(np.concatenate([ResNet_pred, Y_val], axis=1), \n                              columns = ['cx_pred', 'cy_pred', 'cx', 'cy'])\nResNet_results.insert(0, 'img_id', IDs_val)\nprint(ResNet_results.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize some results from the first model\norig = [img_id for img_id in ResNet_results.img_id \n        if 'f' not in img_id]\norig_imgs = ResNet_results[ResNet_results.img_id.isin(orig)]\nselt_imgs = orig_imgs.sample(n=3)\nimg_list = selt_imgs['img_id'].values\ntrue_centers = selt_imgs[['cx', 'cy']].values\npred_centers = selt_imgs[['cx_pred', 'cy_pred']].values\n\ndraw_roi(TRAIN_PATH, img_list, true_centers, pred_centers, \n         rows=2, cols=3, model_name=\"ResNet50\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the ROI centers that human determined (red) along with that model detected\nselt_dots = orig_imgs.sample(n=10)\nimg_list = selt_dots['img_id'].values\ntrue_centers = (selt_dots[['cx', 'cy']].values * 1330).astype(int)\npred_centers = (selt_dots[['cx_pred', 'cy_pred']].values * 1330).astype(int)\n\nplot_roi_centers(true_centers, pred_centers, \"ResNet-50\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the results\nResNet_results.to_csv(\"ResNet_results.csv\")\n\n# Save the model into HDF5 file\nresnet.save(\"ResNet50_BoneCT.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot training history on loss\nplot_history(hist_resnet, 'ResNet-50', xlim=(10, 120), ylim=(0.0, 0.08))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyper-parameters tunning for ResNet-50"},{"metadata":{},"cell_type":"markdown","source":"** Grid search for best hyper-parameters **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conduct randomized grid search to find appropriate hyper-parameters for the ResNet-50 model\n\nresnet = KerasRegressor(build_fn = ResNet50, \n                        input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n                        epochs = 50,\n                        verbose = True)\n\nlr_power = stats.uniform(loc=-3.3, scale=1.3)\nbatch_size = np.power(2, range(3, 11))\ndense_1 = [1024, 512, 256]\ndense_2 = [256, 128, 56]\ndense_3 = [56, 32, 16]\nextra_layers = list(product(dense_1, dense_2, dense_3))\ndropouts = list(product([0.5, 0.25, 0.0], repeat=3))\n\nhparam_dist = {'lr_power': lr_power,\n               'batch_size': batch_size,\n               'extra_layers': extra_layers,\n               'dropouts': dropouts\n              }\n\nhparam_search = RandomizedSearchCV(estimator=resnet,\n                                   param_distributions=hparam_dist,\n                                   n_iter=16, cv=2, verbose=True)\n\nhparam_search.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the results\n\nprint(\"Best mean loss: {:.5f} with\\n {}\".format(-hparam_search.best_score_, hparam_search.best_params_))\nmeans = -hparam_search.cv_results_['mean_test_score']\nstds = hparam_search.cv_results_['std_test_score']\nparams = hparam_search.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"___\" * 10)\n    print(\"%.5f (%.3f) with\\n %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}